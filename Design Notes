The objective of this task is to implement a classifier that takes user input and identifies candidate rows (classes)
from the poem.

Options:
(A) Bag of Words Match Counting
Summary: Count the number of times each word in the input shows up in each row. Return N rows with highest number of
matches (> 0).
Pros:
- Simple to implement.
Cons:
- Information about set of rows isn't leveraged.
- Stop words managed manually (e.g., remove specific words, remove words that are in all rows, etc.).

(B) TF-IDF
Summary: This is an extension of the Bag of Words scenario where we consider the distribution of words across all rows
when determining. This allows stop words to be handled directly within the model.
Pros:
- Uses information from the whole document, which may lead to better accuracy.
- Handles stop words automatically (though not necessarily perfectly).
Cons:
- May not perform well with smaller datasets.

(C) Embeddings (Word2Vec, BERT, etc.)
Summary: These methods learn meaning from context. While effective, implementation of these approaches doesn't seem
feasible in the timeframe available.

(D) Naive Bayes
Summary: Probabilistic approach that considers the frequency of all words in the poem.
Pros:
- Probabilistic framework facilitates interpretation.
Cons:
- May struggle with small size of dataset?

Other thoughts:
Most of these methods nominally use unigram encoding. This means the program won't take advantage of cases where the
user inputs a phrase from the line; information in the relative positioning of the words would be lost. Each could
conceivably be extended to use longer segments, though they may not all work as efficiently when doing so.