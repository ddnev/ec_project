The objective of this task is to implement a classifier that takes user input and identifies candidate rows (classes)
from the poem.

There are a few off-the-shelf approaches to this:
(1) Bag of Words Match Counting
Summary: Count the number of times each word in the input shows up in each row. Return N rows with highest number of
matches (> 0).
Pros:
- Simple to implement.
Cons:
- Information about set of rows isn't leveraged.
- Stop words managed manually (e.g., remove specific words, remove words that are in all rows, etc.).

(2) TF-IDF (Or other vector space representations)
Summary: This is an extension of the Bag of Words scenario where we consider the distribution of words across all rows
when determining. This allows stop words to be handled directly within the model.
Pros:
- Uses information from the whole document, which may lead to better accuracy.
- Handles stop words automatically (though not necessarily perfectly).
Cons:
- May not perform well with smaller datasets.

(3) Naive Bayes
Summary: Probabilistic approach that considers the frequency of all words in the poem.
Pros:
- Uses information from the whole document, which may lead to better accuracy.
- Handles stop words automatically (though not necessarily perfectly).
Cons:
- May not perform well with smaller datasets.

Other thoughts:
All of these methods nominally use unigram encoding. This means the program won't take advantage of cases where the user
inputs a phrase from the line; information in the relative positioning of the words would be lost. Each could
conceivably be extended to use longer segments, though they may not all work as efficiently when doing so.